{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDX Tranche Pricing - Gaussian Copula Model\n",
    "\n",
    "Implementation of one-factor Gaussian copula for CDX.NA.IG.45 tranche pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize_scalar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "constituents = pd.read_csv('../data/cdx_constituents.csv').dropna(subset=['Company', '5Y_Spread'])\nois_curve = pd.read_csv('../data/ois_curve.csv').dropna(subset=['Tenor'])\n\nwith open('../data/cdx_market_data.json', 'r') as f:\n    market_data = json.load(f)\n\nprint(f\"Loaded {len(constituents)} companies\")\nprint(f\"CDS spread range: {constituents['5Y_Spread'].min():.2f} - {constituents['5Y_Spread'].max():.2f} bps\")\nprint(f\"Mean spread: {constituents['5Y_Spread'].mean():.2f} bps\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bootstrap Survival Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5Y default probability range: 1.86% - 13.11%\n",
      "Portfolio avg 5Y PD: 4.63%\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_survival(spread_bps, recovery_rate, maturity=5.0):\n",
    "    spread = spread_bps / 10000.0\n",
    "    hazard_rate = spread / (1 - recovery_rate)\n",
    "    time_points = np.arange(0, maturity + 0.25, 0.25)\n",
    "    survival = np.exp(-hazard_rate * time_points)\n",
    "    return survival\n",
    "\n",
    "survival_curves = []\n",
    "default_probs = []\n",
    "\n",
    "for _, row in constituents.iterrows():\n",
    "    surv = bootstrap_survival(row['5Y_Spread'], row['Recovery'])\n",
    "    survival_curves.append(surv)\n",
    "    default_probs.append(1 - surv[-1])\n",
    "\n",
    "default_probs = np.array(default_probs)\n",
    "weights = constituents['Weight'].values\n",
    "\n",
    "print(f\"5Y default probability range: {default_probs.min()*100:.2f}% - {default_probs.max()*100:.2f}%\")\n",
    "print(f\"Portfolio avg 5Y PD: {np.sum(weights * default_probs)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gaussian Copula Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianCopula:\n",
    "    def __init__(self, rho, n_points=500):\n",
    "        self.rho = rho\n",
    "        self.Y_values = np.linspace(-5, 5, n_points)\n",
    "        pdf = norm.pdf(self.Y_values)\n",
    "        dy = self.Y_values[1] - self.Y_values[0]\n",
    "        self.Y_weights = pdf * dy / (pdf * dy).sum()\n",
    "    \n",
    "    def conditional_pd(self, PD, Y):\n",
    "        if PD <= 0 or PD >= 1:\n",
    "            return max(0, min(1, PD))\n",
    "        K = norm.ppf(PD)\n",
    "        return norm.cdf((K - np.sqrt(self.rho) * Y) / np.sqrt(1 - self.rho))\n",
    "    \n",
    "    def portfolio_loss(self, pds, weights, recovery=0.40):\n",
    "        lgd = 1 - recovery\n",
    "        losses = np.zeros(len(self.Y_values))\n",
    "        \n",
    "        for i, (Y, prob) in enumerate(zip(self.Y_values, self.Y_weights)):\n",
    "            cond_pds = np.array([self.conditional_pd(pd, Y) for pd in pds])\n",
    "            losses[i] = lgd * np.sum(weights * cond_pds)\n",
    "        \n",
    "        return losses, self.Y_weights\n",
    "    \n",
    "    def tranche_el(self, losses, probs, attach, detach):\n",
    "        width = detach - attach\n",
    "        tranche_loss = np.maximum(0, np.minimum(losses - attach, width)) / width\n",
    "        return np.sum(tranche_loss * probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tranche Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_tranches(copula, pds, weights, discount_rate=0.032325, maturity=5.0):\n",
    "    losses, probs = copula.portfolio_loss(pds, weights)\n",
    "    \n",
    "    payment_dates = np.arange(0.25, maturity + 0.25, 0.25)\n",
    "    df = np.exp(-discount_rate * payment_dates)\n",
    "    avg_surv = 1 - np.sum(weights * pds)\n",
    "    rpv01 = np.sum(df * avg_surv * 0.25)\n",
    "    \n",
    "    tranches = [\n",
    "        ('equity_0_3', 0.00, 0.03, 500.0),\n",
    "        ('mezz_3_7', 0.03, 0.07, None),\n",
    "        ('mezz_7_10', 0.07, 0.10, None),\n",
    "        ('senior_10_15', 0.10, 0.15, None),\n",
    "        ('senior_15_100', 0.15, 1.00, None)\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    for name, attach, detach, running in tranches:\n",
    "        el = copula.tranche_el(losses, probs, attach, detach)\n",
    "        spread = (el / rpv01) * 10000\n",
    "        upfront = el - (running / 10000 * rpv01 if running else 0)\n",
    "        \n",
    "        results[name] = {\n",
    "            'el': el * 100,\n",
    "            'spread': spread,\n",
    "            'upfront': upfront * 100 if running else None\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "target_upfront = market_data['market_tranche_prices']['equity_0_3_upfront']\nois_5y = ois_curve[ois_curve['Tenor'] == '5Y']['Mid_Yield'].values[0]\n\ndef objective(rho):\n    try:\n        copula = GaussianCopula(rho, n_points=200)\n        prices = price_tranches(copula, default_probs, weights, ois_5y)\n        \n        # Minimize total weighted error across all tranches\n        total_error = 0\n        weights_obj = [2.0, 1.0, 1.0, 1.0, 1.0]  # Weight equity more, but not exclusively\n        \n        # Equity tranche (upfront)\n        model_upfront = prices['equity_0_3']['upfront']\n        error_equity = ((model_upfront - target_upfront) / 100) ** 2\n        total_error += weights_obj[0] * error_equity\n        \n        # Other tranches (spreads)\n        market_spreads = [\n            market_data['market_tranche_prices']['mezz_3_7'],\n            market_data['market_tranche_prices']['mezz_7_10'],\n            market_data['market_tranche_prices']['senior_10_15'],\n            market_data['market_tranche_prices']['senior_15_100']\n        ]\n        \n        model_spreads = [\n            prices['mezz_3_7']['spread'],\n            prices['mezz_7_10']['spread'],\n            prices['senior_10_15']['spread'],\n            prices['senior_15_100']['spread']\n        ]\n        \n        for i, (model_spread, market_spread) in enumerate(zip(model_spreads, market_spreads)):\n            error = ((model_spread - market_spread) / 100) ** 2  # Normalize to same scale\n            total_error += weights_obj[i+1] * error\n        \n        return total_error\n    except:\n        return 1e10\n\nresult = minimize_scalar(objective, bounds=(0.05, 0.95), method='bounded')\nrho_optimal = result.x\n\nprint(f\"Calibrated correlation: {rho_optimal:.4f} ({rho_optimal*100:.2f}%)\")\nprint(f\"Target equity upfront: {target_upfront:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Pricing with Calibrated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pricing Results:\n",
      "      Tranche      Model     Market      Error\n",
      "   equity_0_3    28.29 %    28.30 %     0.01 %\n",
      "     mezz_3_7 405.20 bps  95.08 bps 310.12 bps\n",
      "    mezz_7_10 184.32 bps 113.10 bps  71.22 bps\n",
      " senior_10_15  87.34 bps  55.94 bps  31.40 bps\n",
      "senior_15_100   3.44 bps  21.72 bps  18.28 bps\n",
      "\n",
      "Absolute Pricing Error (APE): 431.03\n",
      "Mean Absolute Error (MAE): 86.21\n"
     ]
    }
   ],
   "source": [
    "copula_final = GaussianCopula(rho_optimal, n_points=500)\n",
    "model_prices = price_tranches(copula_final, default_probs, weights, ois_5y)\n",
    "\n",
    "market_prices = market_data['market_tranche_prices']\n",
    "\n",
    "comparison = []\n",
    "for name, model in model_prices.items():\n",
    "    if name == 'equity_0_3':\n",
    "        market_val = market_prices['equity_0_3_upfront']\n",
    "        model_val = model['upfront']\n",
    "        error = abs(model_val - market_val)\n",
    "        unit = '%'\n",
    "    else:\n",
    "        market_val = market_prices[name]\n",
    "        model_val = model['spread']\n",
    "        error = abs(model_val - market_val)\n",
    "        unit = 'bps'\n",
    "    \n",
    "    comparison.append({\n",
    "        'Tranche': name,\n",
    "        'Model': f\"{model_val:.2f} {unit}\",\n",
    "        'Market': f\"{market_val:.2f} {unit}\",\n",
    "        'Error': f\"{error:.2f} {unit}\"\n",
    "    })\n",
    "\n",
    "df_result = pd.DataFrame(comparison)\n",
    "print(\"\\nPricing Results:\")\n",
    "print(df_result.to_string(index=False))\n",
    "\n",
    "errors = [abs(model_prices['equity_0_3']['upfront'] - market_prices['equity_0_3_upfront'])]\n",
    "for name in ['mezz_3_7', 'mezz_7_10', 'senior_10_15', 'senior_15_100']:\n",
    "    errors.append(abs(model_prices[name]['spread'] - market_prices[name]))\n",
    "\n",
    "ape = sum(errors)\n",
    "print(f\"\\nAbsolute Pricing Error (APE): {ape:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {ape/len(errors):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Skew Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Base Correlations:\n",
      "  detach_3: 47.67%\n",
      "  detach_7: 47.67%\n",
      "  detach_10: 55.99%\n",
      "  detach_15: 60.33%\n",
      "  detach_100: 67.56%\n",
      "\n",
      "Model single correlation: 33.67%\n",
      "\n",
      "Market correlation skew: 47.67% → 67.56%\n",
      "Spread: 19.90 percentage points\n",
      "\n",
      "Gaussian copula uses single flat correlation - cannot capture skew.\n"
     ]
    }
   ],
   "source": [
    "base_corr = market_data['base_correlations']\n",
    "\n",
    "print(\"Market Base Correlations:\")\n",
    "for k, v in base_corr.items():\n",
    "    print(f\"  {k}: {v:.2f}%\")\n",
    "\n",
    "print(f\"\\nModel single correlation: {rho_optimal*100:.2f}%\")\n",
    "print(f\"\\nMarket correlation skew: {base_corr['detach_3']:.2f}% → {base_corr['detach_100']:.2f}%\")\n",
    "print(f\"Spread: {base_corr['detach_100'] - base_corr['detach_3']:.2f} percentage points\")\n",
    "print(\"\\nGaussian copula uses single flat correlation - cannot capture skew.\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Calculate model-implied base correlations for each tranche\ndef calculate_base_correlation(target_spread, attachment, detachment, is_equity=False):\n    \"\"\"\n    Find the correlation that matches the market spread for a given tranche.\n    This is the base correlation for that detachment point.\n    \"\"\"\n    def objective(rho):\n        copula = GaussianCopula(rho, n_points=200)\n        losses, probs = copula.portfolio_loss(default_probs, weights)\n        el = copula.tranche_el(losses, probs, attachment, detachment)\n        \n        if is_equity:\n            # For equity, match upfront payment\n            model_spread = (el / rpv01) * 10000\n            model_upfront = el - (500 / 10000 * rpv01)\n            return (model_upfront * 100 - target_spread) ** 2\n        else:\n            # For other tranches, match spread\n            model_spread = (el / rpv01) * 10000\n            return (model_spread - target_spread) ** 2\n    \n    try:\n        result = minimize_scalar(objective, bounds=(0.01, 0.99), method='bounded')\n        return result.x * 100  # Return as percentage\n    except:\n        return None\n\n# Calculate base correlations for each detachment point\nmodel_base_corr = {}\n\n# Equity tranche (0-3%)\nmodel_base_corr['detach_3'] = calculate_base_correlation(\n    market_prices['equity_0_3_upfront'], 0.00, 0.03, is_equity=True\n)\n\n# Mezzanine tranches\nmodel_base_corr['detach_7'] = calculate_base_correlation(\n    market_prices['mezz_3_7'], 0.00, 0.07, is_equity=False\n)\n\nmodel_base_corr['detach_10'] = calculate_base_correlation(\n    market_prices['mezz_7_10'], 0.00, 0.10, is_equity=False\n)\n\n# Senior tranches\nmodel_base_corr['detach_15'] = calculate_base_correlation(\n    market_prices['senior_10_15'], 0.00, 0.15, is_equity=False\n)\n\nmodel_base_corr['detach_100'] = calculate_base_correlation(\n    market_prices['senior_15_100'], 0.00, 1.00, is_equity=False\n)\n\nprint(\"\\nModel-Implied Base Correlations:\")\nprint(\"=\"*50)\nprint(f\"{'Detachment':<15} {'Market':<15} {'Model':<15}\")\nprint(\"-\"*50)\nfor key in ['detach_3', 'detach_7', 'detach_10', 'detach_15', 'detach_100']:\n    market_val = base_corr.get(key, 'N/A')\n    model_val = model_base_corr.get(key)\n    if model_val:\n        print(f\"{key:<15} {market_val:>6.2f}%        {model_val:>6.2f}%\")\n    else:\n        print(f\"{key:<15} {market_val:>6.2f}%        {'N/A':>7}\")\n\n# Calculate correlation skew\nif model_base_corr['detach_3'] and model_base_corr['detach_100']:\n    model_skew = model_base_corr['detach_100'] - model_base_corr['detach_3']\n    market_skew = base_corr['detach_100'] - base_corr['detach_3']\n    print(f\"\\nCorrelation Skew:\")\n    print(f\"  Market: {market_skew:.2f} pp\")\n    print(f\"  Model:  {model_skew:.2f} pp\")\n    print(f\"  Difference: {abs(model_skew - market_skew):.2f} pp\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7.5 Calculate Model Base Correlations",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "results = {\n    'calibrated_correlation': float(rho_optimal),\n    'ape': float(ape),\n    'mae': float(ape / len(errors)),\n    'model_prices': {k: {'spread': float(v['spread']), 'upfront': float(v['upfront']) if v['upfront'] else None} \n                     for k, v in model_prices.items()}\n}\n\nwith open('../results/results.json', 'w') as f:\n    json.dump(results, f, indent=2)\n\ndf_result.to_csv('../results/pricing_comparison.csv', index=False)\n\nprint(\"Results saved to results.json and pricing_comparison.csv\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}